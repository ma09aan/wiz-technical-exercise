name: 02 - Build and Deploy Application to EKS

on:
  push:
    branches:
      - main
    paths:
      - 'app/**'
      - 'kubernetes/**'
      - '.github/workflows/02-app-build-deploy.yml' # Trigger on self-change too
  workflow_dispatch:

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  # Ensure PROJECT_NAME secret is set in GitHub repo settings, or hardcode here if preferred.
  # The ECR_REPOSITORY_NAME should match the name given to the aws_ecr_repository resource in Terraform.
  ECR_REPOSITORY_NAME: ${{ secrets.PROJECT_NAME }}-app-repo
  # The EKS_CLUSTER_NAME should match the name of your EKS cluster created by Terraform.
  EKS_CLUSTER_NAME: ${{ secrets.PROJECT_NAME }}-eks-cluster

jobs:
  build-and-push-image:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    permissions: # Required for OIDC if you were to use it, good practice
      id-token: write
      contents: read

    outputs:
      image_tag: ${{ steps.get_image_tag.outputs.tag }}
      image_uri: ${{ steps.build-image.outputs.image }} # This output is used in the next job

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4 # Updated to v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2 # Updated to v2

    - name: Get Image Tag (Short SHA)
      id: get_image_tag
      run: echo "tag=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        # ECR_REPOSITORY_NAME is taken from the job's env context
        IMAGE_TAG: ${{ steps.get_image_tag.outputs.tag }}
      working-directory: ./app
      run: |
        echo "Building image: $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG"
        docker buildx build --platform linux/amd64 -t $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG --push .
        # Output the full image URI
        echo "image=$ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG" >> $GITHUB_OUTPUT
        echo "Pushed image: $ECR_REGISTRY/$ECR_REPOSITORY_NAME:$IMAGE_TAG"

  deploy-to-eks:
    name: Deploy to EKS
    runs-on: ubuntu-latest
    needs: build-and-push-image # Depends on the image being built and URI being outputted

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      # with:
      #   version: 'v1.27.0' # Optionally specify kubectl version

    - name: Configure kubectl for EKS
      env:
        # Ensure AWS_ACCOUNT_ID is set as a GitHub secret for your repository
        AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
      run: |
        aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
        echo "Current kubectl context:"
        kubectl config current-context
        echo "Available contexts:"
        kubectl config get-contexts

    - name: Update Kubernetes deployment with new image
      run: |
        IMAGE_URI_FROM_BUILD="${{ needs.build-and-push-image.outputs.image_uri }}"
        echo "Attempting to use Image URI from build step: '$IMAGE_URI_FROM_BUILD'"

        if [ -z "$IMAGE_URI_FROM_BUILD" ]; then
          echo "::error::Image URI from build step is empty. Cannot update deployment."
          exit 1
        fi
        
        DEPLOYMENT_FILE="kubernetes/03-deployment.yaml"
        PLACEHOLDER_TEXT="image: DYNAMICALLY_REPLACED_BY_CI_CD_PIPELINE" # Ensure this matches your YAML

        echo "Updating $DEPLOYMENT_FILE..."
        # Use a different delimiter for sed if IMAGE_URI_FROM_BUILD contains slashes (which it will)
        # Check if the placeholder exists before attempting to replace
        if grep -q "$PLACEHOLDER_TEXT" "$DEPLOYMENT_FILE"; then
          sed -i "s#${PLACEHOLDER_TEXT}.*#image: ${IMAGE_URI_FROM_BUILD}#g" "$DEPLOYMENT_FILE"
          echo "$DEPLOYMENT_FILE after sed replacement:"
          cat "$DEPLOYMENT_FILE"
          # Verify the replacement worked
          if grep -q "$PLACEHOLDER_TEXT" "$DEPLOYMENT_FILE"; then
            echo "::error::Placeholder text still found in $DEPLOYMENT_FILE after sed. Replacement failed."
            exit 1
          elif ! grep -q "image: ${IMAGE_URI_FROM_BUILD}" "$DEPLOYMENT_FILE"; then
            echo "::error::New image URI not found in $DEPLOYMENT_FILE after sed. Replacement failed."
            exit 1
          else
            echo "Image URI successfully updated in $DEPLOYMENT_FILE."
          fi
        else
          echo "::warning::Placeholder text '$PLACEHOLDER_TEXT' not found in $DEPLOYMENT_FILE. Checking if image is already updated or if placeholder is different."
          # If the placeholder is not found, it might be okay if the image was already updated by a previous run
          # or if the placeholder in the committed file is different. This check prevents unnecessary failure.
          # For this exercise, if it's not found, we'll assume it's okay or was already updated.
          # In a production pipeline, you might want stricter checks or different logic.
        fi

    - name: Deploy to EKS cluster
      run: |
        echo "Applying Kubernetes manifests..."
        kubectl apply -f kubernetes/01-namespace.yaml
        # Ensure the secret data is correctly base64 encoded and the placeholder is replaced before applying
        kubectl apply -f kubernetes/05-secret.yaml 
        kubectl apply -f kubernetes/02-rbac-clusteradmin.yaml
        kubectl apply -f kubernetes/03-deployment.yaml
        kubectl apply -f kubernetes/04-service.yaml
        
        echo "Waiting for deployment rollout to complete..."
        kubectl rollout status deployment/wizapp-deployment -n wizapp --timeout=3m
        
        echo "Application Load Balancer URL (may take a few minutes to become available):"
        # Attempt to get hostname, fall back to IP if hostname is not available
        LB_ADDRESS=$(kubectl get svc wizapp-service -n wizapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || kubectl get svc wizapp-service -n wizapp -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        echo "Load Balancer Address: $LB_ADDRESS"
        if [ -z "$LB_ADDRESS" ]; then
          echo "::warning::Load Balancer address not yet available."
        fi
